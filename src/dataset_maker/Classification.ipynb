{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классификация текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "random.seed(1228)\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "import re\n",
    "from pymystem3 import Mystem\n",
    "import numpy as np\n",
    "import itertools\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from nltk.stem.snowball import RussianStemmer\n",
    "import seaborn as sns\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиение на тестовое и обучающее множество"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Mystem()\n",
    "regex = re.compile(\"[А-Яа-я]+\")\n",
    "\n",
    "def words_only(text, regex=regex):\n",
    "    try:\n",
    "        return \" \".join(regex.findall(text))\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "def lemmatize(text, mystem=m):\n",
    "    try:\n",
    "        return \"\".join(m.lemmatize(text)).strip()  \n",
    "    except:\n",
    "        return \" \"\n",
    "\n",
    "def stemming(text, stemmer = RussianStemmer()):\n",
    "    try:\n",
    "        return \" \".join([stemmer.stem(w) for w in text.split()])\n",
    "    except:\n",
    "        return \" \"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "# print(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "854\n"
     ]
    }
   ],
   "source": [
    "with open(\"/Users/romakindmitriy/PycharmProjects/TelegramParser/docs/stopwords/fullstopwords.txt\", 'r') as f:\n",
    "    stopw = f.readlines()\n",
    "\n",
    "# print(stopw)\n",
    "v_stopwords = list(set([x[:-1] for x in stopw]))\n",
    "print(len(v_stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystopwords = stopwords.words('russian') + v_stopwords\n",
    "mystopwords = list(set(mystopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text, mystopwords = mystopwords):\n",
    "    try:\n",
    "        return \" \".join([token for token in text.split() if not token in mystopwords])\n",
    "    except:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Нет, я вспомнил. есть хорошие новости, с котор...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>В Штатах, кажется, хотят сделать очень невыгод...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>аппаратная дыра в процессорах Intel, а точнее ...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Let’s Encrypt пока что не будет отзывать часть...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Интересное видео с выступлением менеджеров Mic...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  class\n",
       "0  Нет, я вспомнил. есть хорошие новости, с котор...    2.0\n",
       "1  В Штатах, кажется, хотят сделать очень невыгод...    2.0\n",
       "2  аппаратная дыра в процессорах Intel, а точнее ...    5.0\n",
       "3  Let’s Encrypt пока что не будет отзывать часть...    5.0\n",
       "4  Интересное видео с выступлением менеджеров Mic...    2.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = pd.read_csv('./dataset_classes.csv', usecols=['message','class'])\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_1 = d['class'] == 1.\n",
    "filter_2 = d['class'] == 2.\n",
    "filter_3 = d['class'] == 3.\n",
    "filter_4 = d['class'] == 4.\n",
    "filter_5 = d['class'] == 5.\n",
    "# filter_6 = d['class'] == 5\n",
    "\n",
    "data = d.loc[filter_1 | filter_2 | filter_3 | filter_4 | filter_5]\n",
    "# ch = 150\n",
    "# pdlist = [d[filter_1][:ch], d[filter_2][:ch], d[filter_3][:ch], d[filter_4][:ch], d[filter_5][:ch]]\n",
    "# data = pd.concat(pdlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0    799\n",
       "4.0    187\n",
       "1.0    122\n",
       "2.0    118\n",
       "5.0     64\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Нет, я вспомнил. есть хорошие новости, с котор...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>В Штатах, кажется, хотят сделать очень невыгод...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>аппаратная дыра в процессорах Intel, а точнее ...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Let’s Encrypt пока что не будет отзывать часть...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Интересное видео с выступлением менеджеров Mic...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  class\n",
       "0  Нет, я вспомнил. есть хорошие новости, с котор...    2.0\n",
       "1  В Штатах, кажется, хотят сделать очень невыгод...    2.0\n",
       "2  аппаратная дыра в процессорах Intel, а точнее ...    5.0\n",
       "3  Let’s Encrypt пока что не будет отзывать часть...    5.0\n",
       "4  Интересное видео с выступлением менеджеров Mic...    2.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_sample_train = pd.DataFrame(columns=data.columns)\n",
    "# corpus_sample_test = pd.DataFrame(columns=data.columns)\n",
    "\n",
    "# for cl in data['class'].unique():\n",
    "#     corpus_sample = data[data['class']==cl]\n",
    "#     if len(corpus_sample) > 200:\n",
    "#         corpus_sample_train = corpus_sample_train.append(corpus_sample.iloc[:60,:])\n",
    "#         corpus_sample_test = corpus_sample_test.append(corpus_sample.iloc[60:,:])\n",
    "#     elif len(corpus_sample) > 60:\n",
    "#         corpus_sample_train = corpus_sample_train.append(corpus_sample.iloc[:60,:])\n",
    "#         corpus_sample_test = corpus_sample_test.append(corpus_sample.iloc[60:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_sample_train = pd.DataFrame(columns=data.columns)\n",
    "corpus_sample_test = pd.DataFrame(columns=data.columns)\n",
    "\n",
    "for cl in data['class'].unique():\n",
    "    corpus_sample = data[data['class']==cl][20:120]\n",
    "    corpus_sample_train = corpus_sample_train.append(corpus_sample)\n",
    "    corpus_sample_test = corpus_sample_test.append(data[data['class']==cl][:20])\n",
    "    corpus_sample_test = corpus_sample_test.append(data[data['class']==cl][120:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "442"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_sample_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "848"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_sample_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_sample_train.message = corpus_sample_train.message.apply(lemmatize)\n",
    "corpus_sample_test.message = corpus_sample_test.message.apply(lemmatize)\n",
    "corpus_sample_train.message = corpus_sample_train.message.apply(remove_stopwords)\n",
    "corpus_sample_test.message = corpus_sample_test.message.apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>нет, вспомнить. новость, оставлять длинный вых...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>штат, кажется, невыгодный шифрование продукт. ...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>видео выступление менеджер Microsoft, IT-безоп...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>секретный опасност. министерство юстиция сша в...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NYT то, китай технология то, определять, жител...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  class\n",
       "0  нет, вспомнить. новость, оставлять длинный вых...    2.0\n",
       "1  штат, кажется, невыгодный шифрование продукт. ...    2.0\n",
       "4  видео выступление менеджер Microsoft, IT-безоп...    2.0\n",
       "5  секретный опасност. министерство юстиция сша в...    2.0\n",
       "8  NYT то, китай технология то, определять, жител...    2.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_sample_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...imators=10, n_jobs=None, oob_score=False, random_state=None,\n",
       "         verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', BaggingClassifier()),\n",
    "#     RandomForestClassifier\n",
    "#     ('clf', AdaBoostClassifier()),\n",
    "])\n",
    "\n",
    "\n",
    "clf.fit(corpus_sample_train['message'], corpus_sample_train['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = corpus_sample_test['class']\n",
    "predictions = clf.predict(corpus_sample_test['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clf_all_stopwords.sav']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'clf_all_stopwords.sav'\n",
    "joblib.dump(clf, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:   0.55\n",
      "Recall:   0.60\n",
      "F1-measure:   0.50\n",
      "Accuracy:   0.79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.30      0.59      0.39        22\n",
      "         2.0       0.40      0.95      0.56        20\n",
      "         3.0       0.92      0.85      0.89       699\n",
      "         4.0       0.37      0.45      0.40        87\n",
      "         5.0       0.75      0.15      0.25        20\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       848\n",
      "   macro avg       0.55      0.60      0.50       848\n",
      "weighted avg       0.83      0.79      0.80       848\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Precision: {0:6.2f}\".format(precision_score(true, predictions, average='macro')))\n",
    "print(\"Recall: {0:6.2f}\".format(recall_score(true, predictions, average='macro')))\n",
    "print(\"F1-measure: {0:6.2f}\".format(f1_score(true, predictions, average='macro')))\n",
    "print(\"Accuracy: {0:6.2f}\".format(accuracy_score(true, predictions)))\n",
    "print(classification_report(true, predictions))\n",
    "labels = clf.classes_\n",
    "\n",
    "\n",
    "\n",
    "labels = clf.classes_\n",
    "sns.heatmap(data=confusion_matrix(true, predictions), annot=True, fmt=\"d\", cbar=False, xticklabels=labels, yticklabels=labels)\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: text, dtype: object)\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(type(corpus_sample_test['message'][1]))\n",
    "clf.predict(corpus_sample_test['message'][1:2])\n",
    "\n",
    "data = [[corpus_sample_test['message'][1]]] \n",
    "  \n",
    "# Create the pandas DataFrame \n",
    "pdd = pd.DataFrame(data, columns = ['text'])\n",
    "print(pdd['text'][:0])\n",
    "print(type(pdd['text'][:1]))\n",
    "clf.predict(pdd['text'][:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Классификация текстов \n",
    "\n",
    "По мотивам http://nadbordrozd.github.io/blog/2016/05/20/text-classification-with-word2vec/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics import *\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter, defaultdict\n",
    "random.seed(1228)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "import re\n",
    "\n",
    "\n",
    "m = Mystem()\n",
    "\n",
    "\n",
    "regex = re.compile(\"[А-Яа-я:=!\\)\\()A-z\\_\\%/|]+\")\n",
    "\n",
    "def words_only(text, regex=regex):\n",
    "    try:\n",
    "        return \" \".join(regex.findall(text))\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "\n",
    "def lemmatize(text, mystem=m):\n",
    "    try:\n",
    "        return \"\".join(m.lemmatize(text)).strip()  \n",
    "    except:\n",
    "        return \" \"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv('./dataset_classes.csv')\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_1 = d['class'] == 1.\n",
    "filter_2 = d['class'] == 2.\n",
    "filter_3 = d['class'] == 3.\n",
    "filter_4 = d['class'] == 4.\n",
    "filter_5 = d['class'] == 5.\n",
    "filter_6 = d['class'] == 5\n",
    "\n",
    "# df = d.loc[filter_1 | filter_2 | filter_3 | filter_4 | filter_5 | filter_6]\n",
    "ch = 150\n",
    "pdlist = [d[filter_1][:ch], d[filter_2][:ch], d[filter_3][:ch], d[filter_4][:ch], d[filter_5][:ch]]\n",
    "df = pd.concat(pdlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.message.dropna(inplace = True)\n",
    "# len_data = df.message.apply(len)\n",
    "# len_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.message = df.message.apply(words_only)\n",
    "df.message = df.message.apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.message = df.message.apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [df.message.iloc[i].split() for i in range(len(df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec(texts, size=100, window=5, min_count=5, workers=6)\n",
    "model.save(\"sent_w2v.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"sent_w2v.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = len(df.message.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.message.tolist()\n",
    "y = list(df['class'])[:cl]\n",
    "\n",
    "X, y = np.array(X), np.array(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.33)\n",
    "print (\"total train examples %s\" % len(y_train))\n",
    "print (\"total test examples %s\" % len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        # if a text is empty we should return a vector of zeros\n",
    "        # with the same dimensionality as all the other vectors\n",
    "        self.dim = len(w2v.popitem()[1])\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.word2vec[w] for w in words if w in self.word2vec]\n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfidfEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.word2weight = None\n",
    "        self.dim = len(w2v.popitem()[1])\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        tfidf = TfidfVectorizer(analyzer=lambda x: x)\n",
    "        tfidf.fit(X)\n",
    "        max_idf = max(tfidf.idf_)\n",
    "        self.word2weight = defaultdict(\n",
    "            lambda: max_idf,\n",
    "            [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "                np.mean([self.word2vec[w] * self.word2weight[w]\n",
    "                         for w in words if w in self.word2vec] or\n",
    "                        [np.zeros(self.dim)], axis=0)\n",
    "                for words in X\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = dict(zip(model.wv.index2word, model.wv.syn0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "\n",
    "\n",
    "rfc_w2v = Pipeline([\n",
    "    (\"word2vec vectorizer\", MeanEmbeddingVectorizer(w2v)),\n",
    "    (\"extra trees\", RandomForestClassifier(n_estimators=20))])\n",
    "rfc_w2v_tfidf = Pipeline([\n",
    "    (\"word2vec vectorizer\", TfidfEmbeddingVectorizer(w2v)),\n",
    "    (\"extra trees\", RandomForestClassifier(n_estimators=20))])\n",
    "rfc_w2v_tfidf_v1 = Pipeline([\n",
    "    (\"word2vec vectorizer\", TfidfEmbeddingVectorizer(w2v)),\n",
    "    (\"extra trees\", BaggingClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_w2v.fit(X_train,y_train)\n",
    "pred = rfc_w2v.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'rfc_w2v.sav'\n",
    "joblib.dump(rfc_w2v, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision: {0:6.2f}\".format(precision_score(y_test, pred, average='macro')))\n",
    "print(\"Recall: {0:6.2f}\".format(recall_score(y_test, pred, average='macro')))\n",
    "print(\"F1-measure: {0:6.2f}\".format(f1_score(y_test, pred, average='macro')))\n",
    "print(\"Accuracy: {0:6.2f}\".format(accuracy_score(y_test, pred)))\n",
    "print(classification_report(y_test, pred))\n",
    "labels = rfc_w2v.classes_\n",
    "\n",
    "\n",
    "sns.heatmap(data=confusion_matrix(y_test, pred), annot=True, fmt=\"d\", cbar=False, xticklabels=labels, yticklabels=labels)\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_w2v_tfidf.fit(X_train,y_train)\n",
    "pred = rfc_w2v_tfidf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision: {0:6.2f}\".format(precision_score(y_test, pred, average='macro')))\n",
    "print(\"Recall: {0:6.2f}\".format(recall_score(y_test, pred, average='macro')))\n",
    "print(\"F1-measure: {0:6.2f}\".format(f1_score(y_test, pred, average='macro')))\n",
    "print(\"Accuracy: {0:6.2f}\".format(accuracy_score(y_test, pred)))\n",
    "print(classification_report(y_test, pred))\n",
    "labels = rfc_w2v.classes_\n",
    "\n",
    "\n",
    "sns.heatmap(data=confusion_matrix(y_test, pred), annot=True, fmt=\"d\", cbar=False, xticklabels=labels, yticklabels=labels)\n",
    "plt.title(\"Confusion matrix\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_w2v_tfidf_v1.fit(X_train,y_train)\n",
    "pred = rfc_w2v_tfidf_v1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision: {0:6.2f}\".format(precision_score(y_test, pred, average='macro')))\n",
    "print(\"Recall: {0:6.2f}\".format(recall_score(y_test, pred, average='macro')))\n",
    "print(\"F1-measure: {0:6.2f}\".format(f1_score(y_test, pred, average='macro')))\n",
    "print(\"Accuracy: {0:6.2f}\".format(accuracy_score(y_test, pred)))\n",
    "print(classification_report(y_test, pred))\n",
    "labels = rfc_w2v.classes_\n",
    "\n",
    "\n",
    "sns.heatmap(data=confusion_matrix(y_test, pred), annot=True, fmt=\"d\", cbar=False, xticklabels=labels, yticklabels=labels)\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
